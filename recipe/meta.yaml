{% set version = "2.14.99" %}
{% set estimator_version = "2.14.0" %}

package:
  name: tensorflow-split
  version: {{ version }}

source:
  - url: https://github.com/tensorflow/tensorflow/archive/055de2ca51395eb86aa3ef084b858c1e0e02c948.zip
    sha256: f931f5343d907059568fce839e631bbd2fb7ce1f2462464040b3fc2be6dbf566
    patches:
      - patches/0001-loosen-requirements.patch
      - patches/0002-fix-genproto.patch
      - patches/0003-Add-additional-absl_synchronization-linkage-to-gRPC.patch
      - patches/0004-Add-missing-any_invocable-target-to-absel-bazel.patch
      - patches/0005-Fix-missing-abseil-linkages.patch
      - patches/0006-Fix-protobuf_python-for-systemlibs.patch
      - patches/0007-Add-absl_log-systemlib.patch
      - patches/0008-Omit-linking-to-layout_proto_cc-if-protobuf-linkage-.patch
      - patches/0009-Fix-further-abseil-linkage.patch
      - patches/0010-Add-constraint-to-pybind11-systemlib.patch
      - patches/0011-Different-file-ending-for-flatbuffers-LICENSE.patch
      - patches/0012-Use-correct-hermetic-python.patch
      - patches/0013-Add-ducc-to-static_deps.patch

  - url: https://github.com/tensorflow/estimator/archive/refs/tags/v{{ estimator_version.replace(".rc", "-rc") }}.tar.gz
    sha256: 622797bf5311f239c2b123364fa360868ae97d16b678413e5e0633241f7d7d5c
    folder: tensorflow-estimator
  - url: https://raw.githubusercontent.com/jax-ml/ml_dtypes/v0.2.0/ml_dtypes/include/float8.h
    fn: float8.h
    sha256: 7c3d32809adf01e1568434760bf3c347d0ef21d5fc4c5009815a5dd54635ed25

build:
  number: 0
  skip: true  # [win]
  skip: true  # [python_impl == 'pypy']
  skip: true  # [py<39]
  skip: true  # [cuda_compiler_version == "11.2"]

requirements:
  build:
    - perl                                   # [linux]
    - python                                 # [build_platform != target_platform]
    - cython                                 # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - nsync                                  # [build_platform != target_platform]
    - snappy                                 # [build_platform != target_platform]
    - giflib                                 # [build_platform != target_platform]
    - libjpeg-turbo                          # [build_platform != target_platform]
    - icu                                    # [build_platform != target_platform]
    - libpng                                 # [build_platform != target_platform]
    - flatbuffers                            # [build_platform != target_platform]
    - onednn                                 # [build_platform != target_platform]
    - onednn-cpu-threadpool                  # [build_platform != target_platform]
    - pybind11                               # [build_platform != target_platform]
    - numpy                                  # [build_platform != target_platform]
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}                 # [cuda_compiler_version != "None"]
    - bazel >=5.2.0,<6
    - libgrpc
    - libprotobuf
    - nasm
    - sed
    - rsync
    # realpath is not available from the docker image for cuda <= 10.2
    # so we install coreutils here
    - coreutils  # [cuda_compiler_version != "None"]
  host:
    # GPU requirements for CUDA
    - cudnn      # [cuda_compiler_version != "None"]
    - nccl       # [cuda_compiler_version != "None"]
    # conda build requirements
    - python
    - pip
    - packaging
    - zlib
    - libpng
    - libcurl
    - curl         # [win]
    - unzip        # [not win]
    - zip          # [not win]
    - m2-unzip     # [win]
    - m2-zip       # [win]
    - openjdk >=8
    - nsync
    # TF_SYSTEM_LIBS, see usage in
    # https://github.com/tensorflow/tensorflow/blob/v{{ version }}/third_party/systemlibs/syslibs_configure.bzl
    # their versions are specified in
    # https://github.com/tensorflow/tensorflow/blob/v{{ version }}/tensorflow/workspace2.bzl
    # but so far there have been no problems with leaving these
    # unpinned; though some restrictions come in for packages
    # that are also listed as a requirement for the pip_package.
    - libabseil
    - astor
    - cython
    - dill
    - giflib
    - libgrpc
    - flatbuffers
    - icu
    - libjpeg-turbo
    - libpng
    - libprotobuf
    - libprotobuf-python-headers
    - openssl
    - pybind11
    - sqlite
    - snappy
    - zlib
    # requirements specified by the package itself, see
    # github.com/tensorflow/tensorflow/blob/v{{ version }}/tensorflow/tools/pip_package/setup.py
    - absl-py >=1.0.0
    - astunparse >=1.6.0
    - gast >=0.2.1,!=0.5.0,!=0.5.1,!=0.5.2
    - google-pasta >=0.1.1
    - h5py >=2.9.0
    - ml_dtypes 0.2.0
    - numpy
    - opt_einsum >=2.3.2
    - protobuf >=3.20.3,<5,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5
    - python-flatbuffers >=23.5.26
    - six >=1.12
    - termcolor >=1.1.0
    - typing_extensions >=3.6.6
    - wrapt >=1.11.0,<1.15
    # TF-API needs to move in sync
    - tensorboard >=2.13,<2.14
    - keras >=2.13,<2.14

outputs:
  # 2021/12/29: hmaarrfk
  # as of tensorflow 2.7.0 we need the tensorflow-base package to break
  # circular dependency when buliding tensorflow extra packages This annoying
  # circularity is broken upstream by the fact that they have to bootstrap
  # their builds
  - name: tensorflow-base
    script: build_pkg.sh  # [unix]
    script: build_pkg.bat  # [win]
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      # weigh down cpu implementation and give cuda preference
      track_features:
        - tensorflow-cpu          # [cuda_compiler_version == "None"]
      entry_points:
        - toco_from_protos = tensorflow.lite.toco.python.toco_from_protos:main
        - tflite_convert = tensorflow.lite.python.tflite_convert:main
        - toco = tensorflow.lite.python.tflite_convert:main
        - saved_model_cli = tensorflow.python.tools.saved_model_cli:main
        # The tensorboard package adds this entry point.
        # - tensorboard = tensorboard.main:run_main
        - tf_upgrade_v2 = tensorflow.tools.compatibility.tf_upgrade_v2_main:main
        - estimator_ckpt_converter = tensorflow_estimator.python.estimator.tools.checkpoint_converter:main
    requirements:
      # build requirements needs to pick up the compiler run_exports
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}              # [cuda_compiler_version != "None"]
        - python                              # [build_platform != target_platform]
        - cross-python_{{ target_platform }}  # [build_platform != target_platform]
      host:
        # GPU reuqirements
        - cudnn                   # [cuda_compiler_version != "None"]
        - nccl                    # [cuda_compiler_version != "None"]
        # conda build requirements
        - python
        - pip
        - packaging
        - wheel
        # TF_SYSTEM_LIBS
        - libabseil
        - astor
        - cython
        - dill
        - giflib
        - libgrpc
        - flatbuffers
        - icu
        - libjpeg-turbo
        - libcurl
        - libpng
        - libprotobuf
        - libprotobuf-python-headers
        - openssl
        - pybind11
        - snappy
        - sqlite
        - zlib
        # requirements specified by the package itself
        - absl-py >=1.0.0
        - astunparse >=1.6.0
        - gast >=0.2.1,!=0.5.0,!=0.5.1,!=0.5.2
        - google-pasta >=0.1.1
        - h5py >=2.9.0
        - ml_dtypes 0.2.0
        - numpy
        - opt_einsum >=2.3.2
        - protobuf >=3.20.3,<5,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5
        - python-flatbuffers >=23.5.26
        - six >=1.12
        - termcolor >=1.1.0
        - typing_extensions >=3.6.6
        - wrapt >=1.11.0,<1.15
        # TF-API needs to move in sync
        - tensorboard >=2.13,<2.14
        - keras >=2.13,<2.14
      run:
        - python
        - packaging
        - absl-py >=1.0.0
        - astunparse >=1.6.0
        - gast >=0.2.1,!=0.5.0,!=0.5.1,!=0.5.2
        - google-pasta >=0.1.1
        - grpcio {{ libgrpc }}.*
        - h5py >=2.9.0
        - ml_dtypes 0.2.0
        - {{ pin_compatible('numpy', lower_bound='1.22') }}
        - opt_einsum >=2.3.2
        - protobuf >=3.20.3,<5,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5
        - python-flatbuffers >=23.5.26
        - six >=1.12
        - termcolor >=1.1.0
        - typing_extensions >=3.6.6
        - wrapt >=1.11.0,<1.15
        # TF-API needs to move in sync
        - tensorboard >=2.13,<2.14
        - keras >=2.13,<2.14
        # avoid that people without GPUs needlessly download ~0.5-1GB
        - __cuda                                                  # [cuda_compiler_version != "None"]
        - __osx >={{ MACOSX_DEPLOYMENT_TARGET|default("10.9") }}  # [osx and x86_64]
    # TODO: decide on the name of the package
    # run_constrained:
    #   What is the difference between these two packages?
    #   - tensorflow-io-gcs-filesystem >=0.21.0
    #   - tensorflow-io >=0.21.0
    test:
      commands:
        - exit 0

  - name: tensorflow
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      # weigh down cpu implementation and give cuda preference
      track_features:
        - tensorflow-cpu          # [cuda_compiler_version == "None"]
    requirements:
      host:
        # Require python so that the CONDA_PY gets populated
        - python
      run:
        - python
        - {{ pin_subpackage('tensorflow-base', exact=True) }}
        - {{ pin_subpackage('tensorflow-estimator', exact=True) }}
        # avoid that people without GPUs needlessly download ~0.5-1GB
        # This also helps mamba give preference to the CPU build
        - __cuda  # [cuda_compiler_version != "None"]
    test:
      files:
        - test_tensorflow.py
      requires:
        - pip
      imports:
        - tensorflow
      commands:
        - pip check                  # [build_platform == target_platform]
        - cat test_tensorflow.py     # [unix]
        - python test_tensorflow.py  # [build_platform == target_platform]
        - tf_upgrade_v2 --help       # [build_platform == target_platform]
        # --help exits with exit code 1
        - test -x $PREFIX/bin/saved_model_cli  # [unix]
        - tflite_convert --help      # [build_platform == target_platform]
        - toco_from_protos --help    # [build_platform == target_platform]
        - toco --help                # [build_platform == target_platform]

  - name: tensorflow-estimator
    script: build_estimator.sh  # [unix]
    script: build_estimator.bat  # [win]
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        # Keep the cuda compiler here since it helps package solvers
        # decide on the cuda variant
        # https://github.com/conda-forge/tensorflow-feedstock/issues/162
        - {{ compiler('cuda') }}                   # [cuda_compiler_version != "None"]
        - bazel >=5.2.0,<6
        - python                                   # [build_platform != target_platform]
        - cross-python_{{ target_platform }}       # [build_platform != target_platform]
        - libabseil                                # [build_platform != target_platform]
        - libgrpc                                  # [build_platform != target_platform]
        - icu                                      # [build_platform != target_platform]
        - {{ pin_subpackage('tensorflow-base') }}  # [build_platform != target_platform]
      host:
        - python
        - pip
        - packaging
        - setuptools
        - wheel
        # This ensures that a consistent version of openssl is chosen between
        # all packages.
        # https://github.com/conda-forge/conda-forge.github.io/issues/1528
        - openssl
        - {{ pin_subpackage('tensorflow-base', exact=True) }}
      run:
        - python
        - {{ pin_subpackage('tensorflow-base', exact=True) }}
    test:
      requires:
        - pip
      commands:
        - pip check  # [build_platform == target_platform]

  - name: libtensorflow
    script: cp_libtensorflow.sh
    build:
      skip: true  # [win]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      run_exports:
        # tensorflow makes no ABI guarantees, need to pin to what we built with
        - libtensorflow {{ version }}
    requirements:
      # build requirements needs to pick up the compiler run_exports
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        # Keep the cuda compiler here since it helps package solvers
        # decide on the cuda variant
        # https://github.com/conda-forge/tensorflow-feedstock/issues/162
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
      # host requirements to pick up run_exports
      host:
        - libabseil
        - giflib
        - libgrpc
        - icu
        - libjpeg-turbo
        - libcurl
        - libpng
        - libprotobuf
        - openssl
        - snappy
        - sqlite
        - zlib
      run:
        # avoid that people without GPUs needlessly download ~200-300MB
        - __cuda  # [cuda_compiler_version != "None"]
    test:
      files:
        - test_libtensorflow.sh
        - test_c.c
      requires:
        - {{ compiler('c') }}
      commands:
        - test -f $PREFIX/lib/libtensorflow${SHLIB_EXT}  # [cuda_compiler_version == "None"]
        - ./test_libtensorflow.sh                        # [cuda_compiler_version == "None" and build_platform == target_platform]

  - name: libtensorflow_cc
    script: cp_libtensorflow_cc.sh
    build:
      skip: true  # [win]
      string: cuda{{ cuda_compiler_version | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      run_exports:
        # tensorflow makes no ABI guarantees, need to pin to what we built with
        - libtensorflow_cc {{ version }}
    requirements:
      # build requirements needs to pick up the compiler run_exports
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        # Keep the cuda compiler here since it helps package solvers
        # decide on the cuda variant
        # https://github.com/conda-forge/tensorflow-feedstock/issues/162
        - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
      # host requirements to pick up run_exports
      host:
        - flatbuffers
        - giflib
        - icu
        - libabseil
        - libcurl
        - libgrpc
        - libjpeg-turbo
        - libpng
        - libprotobuf
        - openssl
        - snappy
        - sqlite
        - zlib
      run:
        # avoid that people without GPUs needlessly download ~200-300MB
        - __cuda  # [cuda_compiler_version != "None"]
    test:
      files:
        - test_libtensorflow_cc.sh
        - test_cc.cc
      requires:
        - {{ compiler('cxx') }}
      commands:
        - test -f $PREFIX/lib/libtensorflow_cc${SHLIB_EXT}  # [not win and cuda_compiler_version == "None"]
        - ./test_libtensorflow_cc.sh                        # [not win and cuda_compiler_version == "None" and build_platform == target_platform]

  # 2021/08/01, hmaarrfk
  # While this seems like a roundabout way of defining the package name
  # It helps the linter avoid errors on a package not having tests.
  {% set tensorflow_cpu_gpu = "tensorflow-cpu" %}   # [cuda_compiler_version == "None" or cuda_compiler_version is undefined]
  {% set tensorflow_cpu_gpu = "tensorflow-gpu" %}   # [cuda_compiler_version != "None"]
  - name: {{ tensorflow_cpu_gpu }}
    build:
      string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
      string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]
      detect_binary_files_with_prefix: false
    requirements:
      run:
        - {{ pin_subpackage("tensorflow", exact=True) }}
    test:
      imports:
        - tensorflow

about:
  home: http://tensorflow.org/
  license: Apache-2.0
  license_file: LICENSE
  license_family: Apache
  summary: TensorFlow is an end-to-end open source platform for machine learning.
  description: |
    TensorFlow offers multiple levels of abstraction so you can choose the
    right one for your needs. Build and train models by using the high-level
    Keras API, which makes getting started with TensorFlow and machine learning
    easy.
  dev_url: https://github.com/tensorflow/tensorflow
  doc_url: https://www.tensorflow.org/get_started/get_started
  doc_source_url: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/docs_src

extra:
  feedstock-name: tensorflow
  recipe-maintainers:
    - ngam
    - farhantejani
    - ghego
    - h-vetinari
    - hajapy
    - jschueller
    - njzjz
    - waitingkuo
    - xhochy
    - hmaarrfk
    - wolfv
